{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender systems based on collaborative filtering and latent factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to discuss in this notebook an approach to build a recommender system based on using the whole information stored in the user-product ranking matrix. Although here we assume that such matrix gives only **explicit rankings** provided by users to the products they have bought, there are alternative models for the user-product matrix that incorporate other implicit sources of knowledge for the case where no explicit feedback is available from the user. \n",
    "\n",
    "Because we use the whole information in such matrix to predict unknown entries, we say that we follow a collaborative (or global) filtering approach, because the predictions for unknown entries are based on the collected information from all the known entries of the user-product matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None <SparkContext master=local[*] appName=pyspark-shell>\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Our preliminary set-up code\n",
    "#\n",
    "\n",
    "import pyspark\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import sys\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "sc = pyspark.SparkContext('local[*]')\n",
    "\n",
    "print (spark_home, sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## U-V matrix factorization for latent factors discovery\n",
    "\n",
    "The approach to discover latent factors that characterize users and products, is the one based on U-V matrix factorization. The problem formulation is that we want to find a factorization of our user-product matrix as the product of two matrices $U$ and $V$, where:\n",
    "1. Each user will be represented as a row vector with $c$ factors in matrix $U$, so $U$ will be a matrix with $m$ rows and $c$ columns.\n",
    "2. Each product will be represented as a column vector with $c$ factors in matrix $V$, so $V$ will be a matrix with $c$ rows and $n$ columns.\n",
    "\n",
    "Then, given our user-product rating matrix, with $m$ rows (users) and $n$ columns (products) we want to find matrices $U$ and $V$ such:\n",
    "\n",
    "$$ \\overbrace{ \\left( \\begin{matrix}\n",
    "  U_{1,1} & \\cdots & U_{1,c} \\\\\n",
    "   & \\cdots & \\\\\n",
    "  & \\vdots & \\\\\n",
    "  U_{m,1} & \\cdots & U_{m,c}\n",
    " \\end{matrix} \\right) }^{U \\ (m\\times c)} \\times\n",
    " \\overbrace{ \\left( \\begin{matrix}\n",
    "  V_{1,1} & \\cdots & V_{1,n} \\\\\n",
    "   & \\cdots & \\\\\n",
    "  & \\vdots & \\\\\n",
    "  V_{c,1} & \\cdots & V_{c,n}\n",
    " \\end{matrix}  \\right)  }^{V \\ (c\\times n) } \\ = \\  \n",
    "  \\overbrace{ \\left( \\begin{matrix}\n",
    "  M_{1,1} & \\cdots & M_{1,n} \\\\\n",
    "   & \\cdots & \\\\\n",
    "  & \\vdots & \\\\\n",
    "  M_{m,1} & \\cdots & V_{m,n}\n",
    " \\end{matrix}  \\right)  }^{M (m \\times n)}$$\n",
    "\n",
    "Remember that in general the matrix $M$ may have empty entries, but our U-V factorization will provide values for all the entries, so when we say an U-V factorization is good for a partially filled matrix M, we usually mean that it agrees with the value for the filled entries of M. Once we have this factorization, observe that the value of any entry $(i,j)$ of the matrix M, even for unknown entries, is predicted multiplying the row $i$ of matrix $U$ by column $j$ of matrix V, that is:\n",
    "\n",
    "$$ \\hat{M}(i,j) = \\sum_{k=1}^c U_{i,k} * V_{c,j} $$\n",
    "\n",
    "Because it may be not possible to find such **exact** factorization with the desired number of latent factors, finding such factorization is actually presented as an optimization problem, where the goal is to find a factorization with the smallest RMSE error (error computed over the filled entries of M):\n",
    "\n",
    "$$ \\sqrt{\\frac{\\sum_{i,j}(U(row_i) \\ \\cdot \\ V(col_j) - M(i,j))^2}{\\# \\ known \\ entries}} $$\n",
    "\n",
    "where the summatory is over entries $(i,j)$ of the matrix M with known values. However, because we are really more interested in being able to **predict unknown values** of the matrix M, than in predicting the known ones, to avoid **overfitting** to the known value and  have a high error rate for unknown entries, the optimization algorithms usually also allows to consider alternative objective functions that incorporate regularized terms to control the tradeoff between RMSE error and prediction of unknown entries.\n",
    "\n",
    "\n",
    "## Optimization algorithms for U-V matrix factorization\n",
    "\n",
    "We may consider different algorithms for finding a good U-V factorization (with a small RMSE error or any other generalized error function). These are the two main ones:\n",
    "1. Gradient descend: Using the same approach we presentend for finding a linear model, but this time applied to the parameters of our model (the coefficients of the matrices U and V)\n",
    "\n",
    "2. Alternating Least Squares: If we keep fixed one of the two matrices (U or V), the problem becomes a quadratic optimization problem that can be optimally solved in P-time. So, we perform an iterative process where we fix one of them, find the optimal one for the other, and in the next iteration we exchange the roles: the second one is fixed and the first one is optimized. This process is repeated until we reach a fixed point.\n",
    "\n",
    "\n",
    "To know more about this problems and their solving algorithms, a good source of information is the paper:\n",
    "\n",
    "> Yehuda Koren, Robert Bell and Chris Volinsky. *Matrix factorization techniques for recommender systems*. In Computer Journal, IEEE press, Vol 42(8), 2009.\n",
    "\n",
    "and also the book about data mining for big data we recommended for this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider the same example matrix we used in our notebook about clustering algorithms. In particular, let's consider a data base of users, where for each user we store the ratings given by the user to different movies. We first consider the matrix full of entries, but later we consider variations of this matrix where some of the entries will be empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example data\n",
    "#\n",
    "# We have 10 users, and 10 movies: STW1, STW2, STW3, STW4, STW5, STW6\n",
    "#                                  T1, T2, T3 and BaT\n",
    "# Each entry i,j is the rating given by the user in the range [-5.0,5.0]\n",
    "# We can observe that we have 4 clear Star Wars fans (that they also like a \n",
    "# little bit Terminator movies)\n",
    "# We also have four clear Terminator fans (that they also like a little STWs movies)\n",
    "# Finally, we have two clear Breakfast at tiffannies fans (BaT), that they do not\n",
    "# like too much science-fiction movies\n",
    "\n",
    "usersandmovies = [ [3,3,3,5,5,4, 3,3,-1, -1], \\\n",
    "                   [3,3,3,5,5,4, 4,2,0, -1], \\\n",
    "                   [3,3,4,5,5,4, 4,4,1, 0], \\\n",
    "                   [4,3,3,4,5,4, 3,3,1, -1], \\\n",
    "                   [1,1,1,0,1,1, 5,4,2, -1], \\\n",
    "                   [1,2,1,0,1,1, 4,4,2, -1], \\\n",
    "                   [1,2,2,1,1,1, 4,4,2, -1], \\\n",
    "                   [1,2,2,1,1,0, 5,4,3, -1], \\\n",
    "                   [-2,-3,-2,0,-2,-1, 0,0,-1,4], \\\n",
    "                   [-2,-3,-2,0,-2,-1, 0,0,-1,4]   ]\n",
    "\n",
    "# In this first example, that we used also with the clustering algorithms, all the entries are known,\n",
    "# so we will first consider how good is the ALS algorithm decomposing a fully filled matrix as the product\n",
    "# of the two latent-factor based matrices U and V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating\n",
    "\n",
    "# We need a function to convert our matrix format to a RDD of \n",
    "# pyspark.mllib.recommendation.Rating objects:\n",
    "#\n",
    "#    Rating(int(userid),int(productid),float(rating)\n",
    "# \n",
    "# BEWARE: this function works with the whole matrix in the driver memory,\n",
    "# obtaining a python list representation of the ratings to finally get the\n",
    "# RDD. A better (more scalable) version should do this from a RDD with the matrix entries\n",
    "# loaded from a source file, not from a python matrix in main memory\n",
    "\n",
    "def convertMatrixToRatings( matrix ):\n",
    "    ratings = []\n",
    "    for user,userrow in enumerate(matrix):\n",
    "        for product,productrating in enumerate(userrow):\n",
    "            ratings.append( Rating( int(user) , int(product), float(productrating) ) )\n",
    "    return ratings       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error = 0.08866856107494435\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load and parse the data\n",
    "# data = sc.textFile(spark_home+\"data/mllib/als/test.data\")\n",
    "# ratings = data.map(lambda l: l.split(','))\\\n",
    "#    .map(lambda l: Rating(int(l[0]), int(l[1]), float(l[2])))\n",
    "\n",
    "ratings = sc.parallelize( convertMatrixToRatings( usersandmovies ) )\n",
    "\n",
    "# Check the data:\n",
    "# print ratings.collect()\n",
    "\n",
    "\n",
    "# Build the recommendation model using Alternating Least Squares\n",
    "rank = 3\n",
    "numIterations = 10\n",
    "model = ALS.train(ratings, rank, numIterations)\n",
    "\n",
    "# Evaluate the model on training data\n",
    "# First, get the data without the rating values (only user-product IDs)\n",
    "testdata = ratings.map(lambda p: (p[0], p[1]))\n",
    "\n",
    "# Next, Get the predictions obatined with our U-V factorization model\n",
    "predictions = model.predictAll(testdata).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "# join ((u,p), V) and ((u,p), W) to get ((u,p), (V, W))\n",
    "ratesAndPreds = ratings.map( lambda r: ((r[0], r[1]), r[2]) ).join(predictions)\n",
    "\n",
    "## Compute Mean Square error\n",
    "MSE = ratesAndPreds.map(lambda r: (r[1][0] - r[1][1])**2).mean()\n",
    "print(\"Mean Squared Error = \" + str(MSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Users latent factors:\n",
      "(0, array('d', [-1.0632634162902832, -3.317167282104492, 1.033426284790039]))\n",
      "(1, array('d', [-1.170506238937378, -3.213942766189575, 0.9486397504806519]))\n",
      "(2, array('d', [-1.5727169513702393, -3.1935672760009766, 1.2509902715682983]))\n",
      "(3, array('d', [-1.2623188495635986, -2.9727492332458496, 0.6029390692710876]))\n",
      "(4, array('d', [-1.681282639503479, -0.11645570397377014, 0.1271640658378601]))\n",
      "(5, array('d', [-1.5544735193252563, -0.17659440636634827, -0.09581423550844193]))\n",
      "(6, array('d', [-1.5795621871948242, -0.4811013638973236, 0.05381409823894501]))\n",
      "(7, array('d', [-1.8329441547393799, -0.19166715443134308, -0.03150169923901558]))\n",
      "(8, array('d', [0.3472416400909424, 0.6908116340637207, 1.7061084508895874]))\n",
      "(9, array('d', [0.3472416400909424, 0.6908116340637207, 1.7061084508895874]))\n",
      "\n",
      " Products latent factors:\n",
      "(0, array('d', [-0.46577298641204834, -1.0279934406280518, -0.6886447668075562]))\n",
      "(1, array('d', [-0.9108235239982605, -0.9404649138450623, -1.1803969144821167]))\n",
      "(2, array('d', [-0.8003668785095215, -0.8848921060562134, -0.6055119633674622]))\n",
      "(3, array('d', [-0.1126871258020401, -1.2662841081619263, 0.531701385974884]))\n",
      "(4, array('d', [-0.3892841935157776, -1.53623366355896, -0.46788489818573]))\n",
      "(5, array('d', [-0.2701534628868103, -1.1526747941970825, -0.07201100885868073]))\n",
      "(6, array('d', [-2.6899404525756836, 0.1269415020942688, 0.4927728772163391]))\n",
      "(7, array('d', [-2.3964898586273193, 0.14279459416866302, 0.42278018593788147]))\n",
      "(8, array('d', [-1.45009446144104, 0.3639034926891327, -0.44182613492012024]))\n",
      "(9, array('d', [0.49972274899482727, 0.6427972912788391, 1.9459335803985596]))\n"
     ]
    }
   ],
   "source": [
    "# We can also get the U-V factorization, as the set of user features (latent factors) of\n",
    "# the U matrix\n",
    "\n",
    "print (\" Users latent factors:\")\n",
    "for userfactors in model.userFeatures().sortByKey().collect():\n",
    "    print (userfactors)\n",
    "\n",
    "# and the set of product features of the V matrix:\n",
    "print (\"\\n Products latent factors:\")\n",
    "for productfactors in model.productFeatures().sortByKey().collect(): \n",
    "    print (productfactors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Can you identify significant differences between the latent factors for different user groups and product groups ? Observe that the two \"Breakfast at Tiffany's\" fans have clearly different latent factors than the others users\n",
    "\n",
    "Let's next check what happens if there are some missing values in the user-product matrix. Consider the following function to randomly erase $k$ entries from each row of the matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convertMatrixToRatingsWithBlanks( matrix, k ):\n",
    "    ratings = []\n",
    "    for user,userrow in enumerate(matrix):\n",
    "        size = len(userrow)\n",
    "        blanks = random.sample(range(size), k)\n",
    "        for product,productrating in enumerate(userrow):\n",
    "            if (product not in blanks):\n",
    "              ratings.append( Rating( int(user) , int(product), float(productrating) ) )\n",
    "    return ratings      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error = 0.12332159044395823\n"
     ]
    }
   ],
   "source": [
    "ratings2 = sc.parallelize( convertMatrixToRatingsWithBlanks( usersandmovies, 4  ) )\n",
    "\n",
    "# Check the data:\n",
    "# print ratings.collect()\n",
    "\n",
    "\n",
    "# Build the recommendation model using Alternating Least Squares\n",
    "rank = 3\n",
    "numIterations = 10\n",
    "model2 = ALS.train(ratings2, rank, numIterations)\n",
    "\n",
    "# Evaluate the model on training data\n",
    "# First, get the data without the rating values (only user-product IDs)\n",
    "testdata2 = ratings2.map(lambda p: (p[0], p[1]))\n",
    "\n",
    "# Next, Get the predictions obatined with our U-V factorization model\n",
    "predictions2 = model2.predictAll(testdata2).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "# join ((u,p), V) and ((u,p), W) to get ((u,p), (V, W))\n",
    "ratesAndPreds2 = ratings2.map( lambda r: ((r[0], r[1]), r[2]) ).join(predictions2)\n",
    "\n",
    "## Compute Mean Square error\n",
    "MSE2 = ratesAndPreds2.map(lambda r: (r[1][0] - r[1][1])**2).mean()\n",
    "print(\"Mean Squared Error = \" + str(MSE2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the error increases where less entries are available to find a good model, but remember that this does not imply that the model predition on unkown entries will be also worse. Actually, a problem of this factorization approach is that to be able to get a good factor vector for a given user, we need enough known entries for that user. In contrast, in the next notebook we will present a recommender system for products in an on-line store based on direct product-to-product comparison that allows to give recommendations for users from any single previously bought (or ranked) product of that user, so even if the user only made ONE purchase the system will be able to give recommendations, as soon as the total number of user purchases in the on-line store is high enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To know more about the ALS algorithm (and other global filtering algorithms) in spark, check the documentation page:\n",
    "\n",
    "> https://spark.apache.org/docs/1.6.1/mllib-collaborative-filtering.html\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
